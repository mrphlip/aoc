# 3 &ndash; Keeping Up on the Neighbours
This one seemed really fiddly at first, but didn't end up turning out too bad. Having to find all these objects in this grid, and keep track of how they're neighbouring each other, when the numbers can take up multiple digits, looked intimidating at first. But, after taking a couple of passes through the data to extract all of the relevant objects, so we just have a list of symbols (with their location) and a list of numbers (with their location and length), then from there the processing was a lot easier to think about.

I did briefly code the `neighbours` function (which takes a number and returns all the locations around it where we need to check for a symbol) to _exclude_ diagonals, instead of _include_ them, but luckily I caught that mistake quickly.

And then the second half of the puzzle didn't end up being too complicated to build off of this strategy, so it was knocked out in short order.

However, I've started to notice a pattern... all three of the puzzles so far, have been structured such that there is a easy bug you can fall into, which is _not_ tested for by the worked example in the puzzle, but which _is_ tested by the actual puzzle input. So you can easily end up with code that works for the example but gives the wrong answer for the actual puzzle, and this can be infuriating to have to debug.

That is: in day 1, the puzzle does not explicitly warn you that the number words can overlap, and while the examples do include overlapping words at the _start_ of a line, none of them include overlapping words at the _end_ of a line, so if you have a parser that operates strictly left-to-right and does not recognise overlaps (like, for instance, `findAll` methods in most regex libraries), you can pass the examples but fail the real puzzle.

On day 2, the sample input was set up so that, for each game, either there was a reveal with large values (that meant the game would be rejected), or _all_ the values for the game were _very_ small (nowhere near the threshold). The upshot of which is that if you misread the puzzle, and missed the point that these reveals were supposed to be done _with replacement_, and instead tried to take the total of all the reveals for each game, then you'd again pass the examples and fail the real puzzle.

And now, on day 3, the sample grid has the right column completely blank, every character in the final column is a `.`, but this is not true of the actual puzzle input. So if you're trying to find numbers in the grid by finding digits, and then scanning forward in the string looking for a non-digit character, without bounds checks, then you could successfully pass the example, but potentially run off the end of your buffer when parsing the real input. Depending on exactly how you've written your loop (and what language you're using), maybe that means your code crashes (which would be easier to fix), but maybe it means you just don't recognise numbers right at the end of your string, which could give you incorrect results.

Now, for sure, in the past, AoC has had puzzles where the examples don't completely test the puzzle. That's not what they're for, after all. But for them to be three-for-three so far this year, and with these specific gaps, these feel like they were intentionally engineered to be traps, rather than being oversights. Which really feeds into my feeling from day 1, that AoC is _mean_ this year. I won't really know how I feel about this until I have tried the hard puzzles late in the month, if the trend continues that far...

[171/89]
