# 23 &ndash; The day I gave up on Haskell
I tried a _bunch_ of different approaches to this puzzle, in a few different languages, and they were all awful.

For part 1, I built it rather naively in Python, as I often do when I'm going for the leaderboard race... but that implementation was thoroughly unsuitable for solving part 2. There don't seem to be any shortcuts to just running this operation 10<sup>7</sup> times, so it needs to be thoroughly optimised. So my original solution which involved a lot of list slices and list concatenations and whatnot, with all its requisite re-allocation and copying of the lists, was _not_ going to work.

After trying a couple of things in Python, and getting nowhere, I dropped to C, to make sure I had full control over the arrays and wouldn't accidentally write something that involved a reallocation. My first attempt was array-based, with an array to represent the values at each position, paired with a inverse array to give the position for each value (so that we can find the destination cup without having to search)... but actually moving the three cups to their destination was still a big O(n) relocation, and it was not fast enough. I wasted a lot of time on this because I misread my progress meter, and after a few minutes it looked like it was progressing along ok, but after 12 minutes of runtime, it had done _one_ million steps, not _ten_ million. So that wasn't good.

Being able to do the relocation step in linear time seemed like the ideal task for a linked-list, but I was hesitant to do that because of the lookup step to find the destination cup, would still have to be a linear search... I built it anyway, and it was slightly faster, but not by a lot.

What I wanted was to have the best of both worlds: a linked list to store the actual data, but also an array of inverse lookups so the search step is also fast. The problem is, I've thought about a similar idea before: of having a linked list, but also an array from _indexes_ to nodes, for faster random access... and it turns out that, however you slice it, having to update the index blows away any speed you get from the linked list... and that previous thinking lead me to discount this option too early. Because while that doesn't work, that's not what I'm trying to do here &ndash; I'm not trying to have a lookup array of _indexes_ to nodes, I'm trying to have a lookup array of _values_ to nodes. And since all we're doing is rearranging the nodes, that lookup doesn't even have to be updated.

And so I built that &ndash; a big linked list to do all the actual work, and a lookup array to map values to nodes, for fast searches. And suddenly part 2 went from taking a couple hours to run, to taking about 1 and a half seconds. I believe that, with this implementation, only the initial setup and teardown of the lists are O(n)... the actual step process itself is O(1).

So my final solution here is in C (technically C++ but only because I wanted to use `new`/`delete` rather than `malloc`). Could easily build the same thing back in Python. But... Haskell? The algorithm relies very heavily on mutating a doubly-linked list in-place, that's how it gets its speed. I have absolutely no idea how to translate that into Haskell's method of operating, and maintaining that speed.

[62/667]
