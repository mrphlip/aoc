# 16 &ndash; The long data stream
This one... this one broke me.

The first part was pretty simple. Just calculated everything directly and naively &ndash; generate the alternating pattern, zip it with the sequence, multiply and add, generate our result, repeat 100 times. All very fine and simple.

Part 2, though... it was just too much data. And laziness came up to bite me in that I'm pretty sure several of the phases were being calculated at once, and memory was being held for multiple of the phases, which as more than would fit in RAM. And the calculation I was doing was not very clever.

After some work, adding strictness to some of the loops, I got something that was holding steady on RAM usage. And I found the parameters to pass to GHC to get it to use multithreading for some of the big chunky `map`s I was doing. But even with this, it was taking an unbearably long time and not even finishing 1 phase, let alone 100.

I spent a long time trying to figure out what the trick was to make it trivial... obviously there must be something to be done using the fact that the signal is cyclical? But even though I could see ways that calculating the first phase from the original signal could be sped up by using its cyclical nature, that first phase output would _not_ be cyclical, so the remaining 99 phases still have to be done the hard way. And I spent quite a while racking my brains about this.

Eventually I gave up, and consulted the subreddit... and discovered that the answer was _not_ to try to use the cyclical structure to shortcut everything, you still have to do the phases the long way. But that phase calculation could be significantly improved with two main tricks:
1. Since the calculation is mostly performing long sums of consecutive entries in the list, instead maintain an array of running totals over the list, and then finding a sum of a bunch of concurrent values is as simple as the difference of the two ends in the partial-sum array. So to caluclate, say, the 100th value in the phase output, instead of adding up `input[100] + input[101] + ... + input[199] - input[300] - ...`, instead we can just calculate `(sums[199] - sums[99]) - (sums[399] - sums[299]) + ...`, which is a lot faster, especially for the later entries in the list. For the latter half of the list, it's just `sums[end] - sums[ix]` as all the other terms are beyond the end of the list.
2. Position n in a phase's output depends only on values in position n or later in the phase's input... so if you're only trying to read the values from the middle of the end result, you can cut off a bunch from the head of the list before you even start. Which is doubly great because the begninning values are the ones that take the longest to calculate, with part 1.

Either of these, I feel like I _should_ have been able to figure out if I'd stopped to think about optimising the actual phase calculations I was doing. But I never even thought about doing so, because I was too tunnel-visioned on trying to find some pattern in the phase calculations and the cyclic data that would trivialise everything.

And so, while I have a solution, and I have the gold star on my profile, I still consider part B as a loss. Half marks, at best.
